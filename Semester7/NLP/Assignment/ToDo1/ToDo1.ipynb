{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a corpus of at least 10 files (you can copy text from different webpages)\n",
    "Read your corpus\n",
    "Calculate Types\n",
    "Calculate Tokens\n",
    "Calculate Frequency of Each Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTokens=0\n",
    "totalTypes=0\n",
    "totalWordsFrequency={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.txt',\n",
       " '10.txt',\n",
       " '2.txt',\n",
       " '3.txt',\n",
       " '4.txt',\n",
       " '5.txt',\n",
       " '6.txt',\n",
       " '7.txt',\n",
       " '8.txt',\n",
       " '9.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('./txt')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "File 1.txt Number of Tokens:  140\n",
      "File 1.txt Number of Types:  109\n",
      "File 1.txt Word Frequency:  {'When': 1, 'most': 1, 'people': 1, 'hear': 1, '“Machine': 1, 'Learning,”': 1, 'they': 1, 'picture': 1, 'a': 5, 'robot:': 1, 'dependable': 1, 'but‐': 1, 'ler': 1, 'or': 1, 'deadly': 1, 'Terminator,': 1, 'depending': 1, 'on': 1, 'who': 1, 'you': 3, 'ask.': 1, 'But': 2, 'Machine': 2, 'Learning': 2, 'is': 1, 'not': 2, 'just': 1, 'futuristic': 1, 'fantasy;': 1, 'it’s': 1, 'already': 1, 'here.': 1, 'In': 1, 'fact,': 1, 'it': 2, 'has': 2, 'been': 1, 'around': 1, 'for': 1, 'decades': 1, 'in': 2, 'some': 1, 'specialized': 1, 'applications,': 1, 'such': 1, 'as': 3, 'Optical': 1, 'Character': 1, 'Recognition': 1, '(OCR).': 1, 'the': 5, 'first': 1, 'ML': 2, 'application': 1, 'that': 4, 'really': 1, 'became': 1, 'mainstream,': 1, 'improving': 1, 'lives': 1, 'of': 5, 'hundreds': 3, 'millions': 1, 'people,': 1, 'took': 1, 'over': 1, 'world': 1, 'back': 1, '1990s:': 1, 'spam': 2, 'filter.': 1, 'It’s': 1, 'exactly': 1, 'self-aware': 1, 'Skynet,': 1, 'but': 1, 'does': 1, 'technically': 1, 'qualify': 1, '(it': 1, 'actually': 1, 'learned': 1, 'so': 1, 'well': 1, 'seldom': 1, 'need': 1, 'to': 2, 'flag': 1, 'an': 1, 'email': 1, 'anymore).': 1, 'It': 1, 'was': 1, 'followed': 1, 'by': 1, 'applications': 1, 'now': 1, 'quietly': 1, 'power': 1, 'products': 1, 'and': 1, 'features': 1, 'use': 1, 'regularly,': 1, 'from': 1, 'better': 1, 'recommendations': 1, 'voice': 1, 'search.': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 10.txt Number of Tokens:  53\n",
      "File 10.txt Number of Types:  45\n",
      "File 10.txt Word Frequency:  {'In': 1, 'contrast,': 1, 'a': 1, 'spam': 3, 'filter': 1, 'based': 1, 'on': 1, 'Machine': 1, 'Learning': 1, 'techniques': 1, 'automatically': 1, 'learns': 1, 'which': 1, 'words': 2, 'and': 2, 'phrases': 1, 'are': 1, 'good': 1, 'predictors': 1, 'of': 2, 'by': 1, 'detecting': 1, 'unusually': 1, 'fre‐': 1, 'quent': 1, 'patterns': 1, 'in': 1, 'the': 2, 'examples': 2, 'compared': 1, 'to': 2, 'ham': 1, '(Figure': 1, '1-2).': 1, 'The': 1, 'program': 1, 'is': 1, 'much': 1, 'shorter,': 1, 'easier': 1, 'maintain,': 1, 'most': 1, 'likely': 1, 'more': 1, 'accurate.': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 2.txt Number of Tokens:  58\n",
      "File 2.txt Number of Types:  46\n",
      "File 2.txt Word Frequency:  {'Where': 1, 'does': 3, 'Machine': 2, 'Learning': 2, 'start': 2, 'and': 2, 'where': 1, 'it': 4, 'end?': 1, 'What': 1, 'exactly': 1, 'mean': 1, 'for': 1, 'a': 2, 'machine': 1, 'to': 2, 'learn': 1, 'something?': 2, 'If': 1, 'I': 1, 'download': 1, 'copy': 1, 'of': 1, 'Wikipedia,': 1, 'has': 1, 'my': 1, 'computer': 1, 'really': 1, 'learned': 1, 'Is': 1, 'suddenly': 1, 'smarter?': 1, 'In': 1, 'this': 1, 'chapter': 1, 'we': 1, 'will': 1, 'by': 1, 'clarifying': 1, 'what': 1, 'is': 1, 'why': 1, 'you': 1, 'may': 1, 'want': 1, 'use': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 3.txt Number of Tokens:  72\n",
      "File 3.txt Number of Types:  50\n",
      "File 3.txt Word Frequency:  {'Then,': 1, 'before': 1, 'we': 3, 'set': 1, 'out': 1, 'to': 2, 'explore': 1, 'the': 6, 'Machine': 2, 'Learning': 2, 'continent,': 1, 'will': 2, 'take': 1, 'a': 3, 'look': 2, 'at': 2, 'map': 1, 'and': 4, 'learn': 1, 'about': 1, 'main': 2, 'regions': 1, 'most': 1, 'notable': 1, 'landmarks:': 1, 'supervised': 1, 'versus': 3, 'unsupervised': 1, 'learning,': 2, 'online': 1, 'batch': 1, 'instance\\x02based': 1, 'model-based': 1, 'learning.': 1, 'Then': 1, 'workflow': 1, 'of': 1, 'typical': 1, 'ML': 1, 'project,': 1, 'discuss': 1, 'challenges': 1, 'you': 1, 'may': 1, 'face,': 1, 'cover': 1, 'how': 1, 'evaluate': 1, 'fine-tune': 1, 'system.': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 4.txt Number of Tokens:  62\n",
      "File 4.txt Number of Types:  53\n",
      "File 4.txt Word Frequency:  {'This': 1, 'chapter': 2, 'introduces': 1, 'a': 3, 'lot': 1, 'of': 2, 'fundamental': 1, 'concepts': 1, '(and': 1, 'jargon)': 1, 'that': 1, 'every': 1, 'data': 1, 'scientist': 1, 'should': 2, 'know': 1, 'by': 1, 'heart.': 1, 'It': 1, 'will': 1, 'be': 1, 'high-level': 1, 'overview': 1, '(it’s': 1, 'the': 3, 'only': 1, 'without': 1, 'much': 1, 'code),': 1, 'all': 1, 'rather': 1, 'simple,': 1, 'but': 1, 'you': 2, 'make': 1, 'sure': 1, 'everything': 1, 'is': 1, 'crystal': 1, 'clear': 1, 'to': 2, 'before': 1, 'continuing': 1, 'on': 1, 'rest': 1, 'book.': 1, 'So': 1, 'grab': 1, 'coffee': 1, 'and': 1, 'let’s': 1, 'get': 1, 'started!': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 5.txt Number of Tokens:  86\n",
      "File 5.txt Number of Types:  67\n",
      "File 5.txt Word Frequency:  {'Machine': 1, 'Learning': 2, 'is': 4, 'the': 2, 'science': 1, '(and': 1, 'art)': 1, 'of': 2, 'programming': 1, 'computers': 2, 'so': 1, 'they': 1, 'can': 1, 'learn': 3, 'from': 2, 'data.': 1, 'Here': 1, 'a': 2, 'slightly': 1, 'more': 2, 'general': 1, 'definition:': 1, '[Machine': 1, 'the]': 1, 'field': 1, 'study': 1, 'that': 1, 'gives': 1, 'ability': 1, 'to': 3, 'without': 1, 'being': 1, 'explicitly': 1, 'programmed.': 1, '—Arthur': 1, 'Samuel,': 1, '1959': 1, 'And': 1, 'engineering-oriented': 1, 'one:': 1, 'A': 1, 'computer': 1, 'program': 1, 'said': 1, 'experience': 2, 'E': 1, 'with': 2, 'respect': 1, 'some': 2, 'task': 1, 'T': 1, 'and': 1, 'performance': 2, 'measure': 1, 'P,': 2, 'if': 1, 'its': 1, 'on': 1, 'T,': 1, 'as': 1, 'measured': 1, 'by': 1, 'improves': 1, 'E.': 1, '—Tom': 1, 'Mitchell,': 1, '1997': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 6.txt Number of Tokens:  111\n",
      "File 6.txt Number of Types:  76\n",
      "File 6.txt Word Frequency:  {'Your': 1, 'spam': 3, 'filter': 1, 'is': 6, 'a': 2, 'Machine': 1, 'Learning': 1, 'program': 1, 'that,': 1, 'given': 1, 'examples': 3, 'of': 3, 'emails': 1, '(e.g.,': 1, 'flagged': 1, 'by': 1, 'users)': 1, 'and': 3, 'regular': 1, '(nonspam,': 1, 'also': 1, 'called': 4, '“ham”)': 1, 'emails,': 2, 'can': 2, 'learn': 2, 'to': 4, 'flag': 2, 'spam.': 1, 'The': 1, 'that': 1, 'the': 7, 'system': 1, 'uses': 1, 'are': 1, 'train‐': 1, 'ing': 1, 'set.': 1, 'Each': 1, 'training': 3, 'example': 1, 'instance': 1, '(or': 1, 'sample).': 1, 'In': 1, 'this': 1, 'case,': 1, 'task': 1, 'T': 1, 'for': 2, 'new': 1, 'experience': 1, 'E': 1, 'data,': 1, 'performance': 2, 'measure': 2, 'P': 1, 'needs': 1, 'be': 1, 'defined;': 1, 'example,': 1, 'you': 1, 'use': 1, 'ratio': 1, 'correctly': 1, 'classified': 1, 'emails.': 1, 'This': 1, 'particular': 1, 'accuracy,': 1, 'it': 1, 'often': 1, 'used': 1, 'in': 1, 'classification': 1, 'tasks.': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 7.txt Number of Tokens:  53\n",
      "File 7.txt Number of Types:  44\n",
      "File 7.txt Word Frequency:  {'If': 1, 'you': 2, 'just': 1, 'download': 1, 'a': 4, 'copy': 2, 'of': 2, 'Wikipedia,': 1, 'your': 1, 'computer': 1, 'has': 1, 'lot': 1, 'more': 1, 'data,': 1, 'but': 1, 'it': 1, 'is': 2, 'not': 2, 'suddenly': 1, 'better': 1, 'at': 1, 'any': 1, 'task.': 1, 'Thus,': 1, 'downloading': 1, 'Wikipedia': 1, 'Machine': 2, 'Learning.': 1, 'Why': 1, 'Use': 1, 'Learning?': 1, 'Consider': 1, 'how': 1, 'would': 1, 'write': 1, 'spam': 1, 'filter': 1, 'using': 1, 'traditional': 1, 'programming': 1, 'techni‐': 1, 'ques': 1, '(Figure': 1, '1-1):': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 8.txt Number of Tokens:  58\n",
      "File 8.txt Number of Types:  48\n",
      "File 8.txt Word Frequency:  {'First': 1, 'you': 2, 'would': 2, 'consider': 1, 'what': 1, 'spam': 1, 'typically': 1, 'looks': 1, 'like.': 1, 'You': 1, 'might': 1, 'notice': 2, 'that': 1, 'some': 1, 'words': 1, 'or': 1, 'phrases': 1, '(such': 1, 'as': 1, '“4U,”': 1, '“credit': 1, 'card,”': 1, '“free,”': 1, 'and': 2, '“amazing”)': 1, 'tend': 1, 'to': 1, 'come': 1, 'up': 1, 'a': 2, 'lot': 1, 'in': 2, 'the': 4, 'subject': 1, 'line.': 1, 'Perhaps': 1, 'also': 1, 'few': 1, 'other': 2, 'pat‐': 1, 'terns': 1, 'sender’s': 1, 'name,': 1, 'email’s': 1, 'body,': 1, 'parts': 1, 'of': 1, 'email.': 1}\n",
      "\n",
      "\n",
      "\n",
      "File 9.txt Number of Tokens:  48\n",
      "File 9.txt Number of Types:  38\n",
      "File 9.txt Word Frequency:  {'You': 2, 'would': 3, 'write': 1, 'a': 2, 'detection': 1, 'algorithm': 1, 'for': 1, 'each': 1, 'of': 2, 'the': 1, 'patterns': 2, 'that': 1, 'you': 1, 'noticed,': 1, 'and': 3, 'your': 2, 'program': 2, 'flag': 1, 'emails': 1, 'as': 1, 'spam': 1, 'if': 1, 'number': 1, 'these': 1, 'were': 1, 'detected.': 1, 'test': 1, 'repeat': 1, 'steps': 1, '1': 1, '2': 1, 'until': 1, 'it': 1, 'was': 1, 'good': 1, 'enough': 1, 'to': 1, 'launch.': 1}\n",
      "\n",
      "\n",
      "\n",
      "Total Number of Tokens:  741\n",
      "Total Number of Types:  576\n",
      "Total Word Frequency:  {'When': 1, 'most': 3, 'people': 1, 'hear': 1, '“Machine': 1, 'Learning,”': 1, 'they': 2, 'picture': 1, 'a': 26, 'robot:': 1, 'dependable': 1, 'but‐': 1, 'ler': 1, 'or': 2, 'deadly': 1, 'Terminator,': 1, 'depending': 1, 'on': 4, 'who': 1, 'you': 13, 'ask.': 1, 'But': 2, 'Machine': 11, 'Learning': 10, 'is': 16, 'not': 4, 'just': 2, 'futuristic': 1, 'fantasy;': 1, 'it’s': 1, 'already': 1, 'here.': 1, 'In': 4, 'fact,': 1, 'it': 9, 'has': 4, 'been': 1, 'around': 1, 'for': 5, 'decades': 1, 'in': 6, 'some': 4, 'specialized': 1, 'applications,': 1, 'such': 1, 'as': 6, 'Optical': 1, 'Character': 1, 'Recognition': 1, '(OCR).': 1, 'the': 30, 'first': 1, 'ML': 3, 'application': 1, 'that': 9, 'really': 2, 'became': 1, 'mainstream,': 1, 'improving': 1, 'lives': 1, 'of': 21, 'hundreds': 3, 'millions': 1, 'people,': 1, 'took': 1, 'over': 1, 'world': 1, 'back': 1, '1990s:': 1, 'spam': 11, 'filter.': 1, 'It’s': 1, 'exactly': 2, 'self-aware': 1, 'Skynet,': 1, 'but': 3, 'does': 4, 'technically': 1, 'qualify': 1, '(it': 1, 'actually': 1, 'learned': 2, 'so': 2, 'well': 1, 'seldom': 1, 'need': 1, 'to': 19, 'flag': 4, 'an': 1, 'email': 1, 'anymore).': 1, 'It': 2, 'was': 2, 'followed': 1, 'by': 6, 'applications': 1, 'now': 1, 'quietly': 1, 'power': 1, 'products': 1, 'and': 19, 'features': 1, 'use': 3, 'regularly,': 1, 'from': 3, 'better': 2, 'recommendations': 1, 'voice': 1, 'search.': 1, 'contrast,': 1, 'filter': 3, 'based': 1, 'techniques': 1, 'automatically': 1, 'learns': 1, 'which': 1, 'words': 3, 'phrases': 2, 'are': 2, 'good': 2, 'predictors': 1, 'detecting': 1, 'unusually': 1, 'fre‐': 1, 'quent': 1, 'patterns': 3, 'examples': 5, 'compared': 1, 'ham': 1, '(Figure': 2, '1-2).': 1, 'The': 2, 'program': 5, 'much': 2, 'shorter,': 1, 'easier': 1, 'maintain,': 1, 'likely': 1, 'more': 4, 'accurate.': 1, 'Where': 1, 'start': 2, 'where': 1, 'end?': 1, 'What': 1, 'mean': 1, 'machine': 1, 'learn': 7, 'something?': 2, 'If': 2, 'I': 1, 'download': 2, 'copy': 3, 'Wikipedia,': 2, 'my': 1, 'computer': 3, 'Is': 1, 'suddenly': 2, 'smarter?': 1, 'this': 2, 'chapter': 3, 'we': 4, 'will': 4, 'clarifying': 1, 'what': 2, 'why': 1, 'may': 2, 'want': 1, 'Then,': 1, 'before': 2, 'set': 1, 'out': 1, 'explore': 1, 'continent,': 1, 'take': 1, 'look': 2, 'at': 3, 'map': 1, 'about': 1, 'main': 2, 'regions': 1, 'notable': 1, 'landmarks:': 1, 'supervised': 1, 'versus': 3, 'unsupervised': 1, 'learning,': 2, 'online': 1, 'batch': 1, 'instance\\x02based': 1, 'model-based': 1, 'learning.': 1, 'Then': 1, 'workflow': 1, 'typical': 1, 'project,': 1, 'discuss': 1, 'challenges': 1, 'face,': 1, 'cover': 1, 'how': 2, 'evaluate': 1, 'fine-tune': 1, 'system.': 1, 'This': 2, 'introduces': 1, 'lot': 3, 'fundamental': 1, 'concepts': 1, '(and': 2, 'jargon)': 1, 'every': 1, 'data': 1, 'scientist': 1, 'should': 2, 'know': 1, 'heart.': 1, 'be': 2, 'high-level': 1, 'overview': 1, '(it’s': 1, 'only': 1, 'without': 2, 'code),': 1, 'all': 1, 'rather': 1, 'simple,': 1, 'make': 1, 'sure': 1, 'everything': 1, 'crystal': 1, 'clear': 1, 'continuing': 1, 'rest': 1, 'book.': 1, 'So': 1, 'grab': 1, 'coffee': 1, 'let’s': 1, 'get': 1, 'started!': 1, 'science': 1, 'art)': 1, 'programming': 2, 'computers': 2, 'can': 3, 'data.': 1, 'Here': 1, 'slightly': 1, 'general': 1, 'definition:': 1, '[Machine': 1, 'the]': 1, 'field': 1, 'study': 1, 'gives': 1, 'ability': 1, 'being': 1, 'explicitly': 1, 'programmed.': 1, '—Arthur': 1, 'Samuel,': 1, '1959': 1, 'And': 1, 'engineering-oriented': 1, 'one:': 1, 'A': 1, 'said': 1, 'experience': 3, 'E': 2, 'with': 2, 'respect': 1, 'task': 2, 'T': 2, 'performance': 4, 'measure': 3, 'P,': 2, 'if': 2, 'its': 1, 'T,': 1, 'measured': 1, 'improves': 1, 'E.': 1, '—Tom': 1, 'Mitchell,': 1, '1997': 1, 'Your': 1, 'that,': 1, 'given': 1, 'emails': 2, '(e.g.,': 1, 'flagged': 1, 'users)': 1, 'regular': 1, '(nonspam,': 1, 'also': 2, 'called': 4, '“ham”)': 1, 'emails,': 2, 'spam.': 1, 'system': 1, 'uses': 1, 'train‐': 1, 'ing': 1, 'set.': 1, 'Each': 1, 'training': 3, 'example': 1, 'instance': 1, '(or': 1, 'sample).': 1, 'case,': 1, 'new': 1, 'data,': 2, 'P': 1, 'needs': 1, 'defined;': 1, 'example,': 1, 'ratio': 1, 'correctly': 1, 'classified': 1, 'emails.': 1, 'particular': 1, 'accuracy,': 1, 'often': 1, 'used': 1, 'classification': 1, 'tasks.': 1, 'your': 3, 'any': 1, 'task.': 1, 'Thus,': 1, 'downloading': 1, 'Wikipedia': 1, 'Learning.': 1, 'Why': 1, 'Use': 1, 'Learning?': 1, 'Consider': 1, 'would': 6, 'write': 2, 'using': 1, 'traditional': 1, 'techni‐': 1, 'ques': 1, '1-1):': 1, 'First': 1, 'consider': 1, 'typically': 1, 'looks': 1, 'like.': 1, 'You': 3, 'might': 1, 'notice': 2, '(such': 1, '“4U,”': 1, '“credit': 1, 'card,”': 1, '“free,”': 1, '“amazing”)': 1, 'tend': 1, 'come': 1, 'up': 1, 'subject': 1, 'line.': 1, 'Perhaps': 1, 'few': 1, 'other': 2, 'pat‐': 1, 'terns': 1, 'sender’s': 1, 'name,': 1, 'email’s': 1, 'body,': 1, 'parts': 1, 'email.': 1, 'detection': 1, 'algorithm': 1, 'each': 1, 'noticed,': 1, 'number': 1, 'these': 1, 'were': 1, 'detected.': 1, 'test': 1, 'repeat': 1, 'steps': 1, '1': 1, '2': 1, 'until': 1, 'enough': 1, 'launch.': 1}\n"
     ]
    }
   ],
   "source": [
    "for i in files:\n",
    "    f = open('./txt/'+str(i), \"r\",encoding=\"utf8\")\n",
    "\n",
    "    file=f.read()\n",
    "    file=file.split()\n",
    "    numberOfTokens=len(file)\n",
    "    numberOfType=len(set(file))\n",
    "    wordFrequency={}\n",
    "    for word in file:\n",
    "        if word in wordFrequency:\n",
    "            wordFrequency[word]+=1\n",
    "        else:\n",
    "            wordFrequency[word]=1\n",
    "    \n",
    "    totalTokens+=numberOfTokens\n",
    "    totalTypes+=numberOfType\n",
    "    for key in wordFrequency:\n",
    "        if key in totalWordsFrequency:\n",
    "            totalWordsFrequency[key]+=wordFrequency[key]\n",
    "        else:\n",
    "            totalWordsFrequency[key]=wordFrequency[key]\n",
    "    \n",
    "    print(\"\\n\\n\")            \n",
    "    print(\"File \"+ str(i) +\" Number of Tokens: \",numberOfTokens)\n",
    "    print(\"File \"+ str(i) +\" Number of Types: \",numberOfType)\n",
    "    print(\"File \"+ str(i) +\" Word Frequency: \",wordFrequency)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Total Number of Tokens: \",totalTokens)\n",
    "print(\"Total Number of Types: \",totalTypes)\n",
    "print(\"Total Word Frequency: \",totalWordsFrequency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
